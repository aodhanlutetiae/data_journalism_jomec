**PREPARATORY WORK**

Do
- Install requests, beautiful soup, lxml, scrapy

Review case studies (why and how journalists scrape)
- story 1
- story 2
- story 3

**CONCEPTS**

- =IMPORTHTML
- Headers
- Ethical & legal scraping
- Requests
- Beautiful soup and Xpath for parsing
- Plotting scraping using pseudocode
- AJAX and rendering client side
- Spiders via Scrapy

[Not covered: GUIs, Openrefine, Outwithub]


**PRACTICE**

Scrape [Jomec staff page](https://www.cardiff.ac.uk/journalism-media-and-culture/people/academic-staff)
for basic staff contact info

[Cardiff potholes?](https://www.fillthathole.org.uk/authority/cardiff/hazards?sort=asc&order=Added)
[Cardiff bookies](https://www.yell.com/ucs/UcsSearchAction.do?keywords=Bookmakers&location=cardiff%2C+United+Kingdom&scrambleSeed=1005010098)

Scrape [this Wales Brexit website without any datafile](https://www.electoralcommission.org.uk/who-we-are-and-what-we-do/elections-and-referendums/past-elections-and-referendums/eu-referendum/results-and-turnout-eu-referendum/eu-referendum-results-region-wales)

Scrape a selection of [the BBC's 2019 UK election results](https://www.bbc.co.uk/news/politics/constituencies/E14000546) using constituency codes

Scrape [Register of Members' Financial Interests](https://publications.parliament.uk/pa/cm/cmregmem/201012/contents.htm)
1. List of the Members
2. A single Member
3. Three consecutive Members

Do a bit of the Bloomberg scrape?

Locate dynamically loading audiovisual files

Scrape a dynamic webpage

Build a pipeline using Scrapy

**RESOURCES**
