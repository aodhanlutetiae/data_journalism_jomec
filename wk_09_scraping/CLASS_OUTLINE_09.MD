**PREPARATORY WORK**

— Do
- Test for / Install requests, beautiful soup, gazpacho, lxml, scrapy, selenium for notebooks
- On Chrome install plugins: Web scraper, Scraper, Downthemall

— Review case studies
- [Heathrow noise complaint every five minutes](https://www.bbc.co.uk/news/uk-england-37803205) & [code](https://onlinejournalismblog.com/2016/11/29/how-the-bbc-england-data-unit-scraped-airport-noise-complaints/)
- [World Cup 2018: France won but how did Ligue 1 fare?](https://www.dw.com/en/world-cup-2018-france-won-but-how-did-ligue-1-fare/a-44705606) & [code](https://github.com/dw-data/wm2018?utm_source=sendinblue&utm_campaign=back_up_copy_Conversations_with_Data_October_scraping)
- [UK election results 2019](https://github.com/aodhanlutetiae/uk_election_2019)
- [Rail fares increases: charts explain passengers' frustration](https://www.bbc.co.uk/news/uk-england-46606525) & [code](https://github.com/BBC-Data-Unit/rail-fare-increases-2019)

**CONCEPTS**

- =IMPORTHTML(): tables, 'ol's, 'ul's & =IMPORTXML(): xpath & =IMPORTFEED()
- Headers
- Ethical & legal scraping
- Requests
- Beautiful soup and Xpath for parsing
- Spiders via Scrapy
- AJAX and rendering client side (selenium)
- scraping data from viz and maps

[Not covered: GUIs / plugins, Openrefine, Outwithub]


**PRACTICE**

Scrape [Jomec staff page](https://www.cardiff.ac.uk/journalism-media-and-culture/people/academic-staff)
for basic staff contact info

[Cardiff potholes?](https://www.fillthathole.org.uk/authority/cardiff/hazards?sort=asc&order=Added)
[Cardiff bookies](https://www.yell.com/ucs/UcsSearchAction.do?keywords=Bookmakers&location=cardiff%2C+United+Kingdom&scrambleSeed=1005010098)

Scrape [this Wales Brexit website without any datafile](https://www.electoralcommission.org.uk/who-we-are-and-what-we-do/elections-and-referendums/past-elections-and-referendums/eu-referendum/results-and-turnout-eu-referendum/eu-referendum-results-region-wales)

Scrape a selection of [the BBC's 2019 UK election results](https://www.bbc.co.uk/news/politics/constituencies/E14000546) using constituency codes

Scrape [Register of Members' Financial Interests](https://publications.parliament.uk/pa/cm/cmregmem/201012/contents.htm)
1. List of the Members
2. A single Member
3. Three consecutive Members

Do a bit of the Bloomberg scrape?

Locate dynamically loading audiovisual files

Scrape a dynamic webpage

Build a pipeline using Scrapy

Scrape the Lords? all 800+


**RESOURCES**

[Datacamp course on xpath and scrapy](https://learn.datacamp.com/courses/web-scraping-with-python)
